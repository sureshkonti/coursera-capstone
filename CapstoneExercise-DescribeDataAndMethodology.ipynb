{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Data", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "    The initial Data needed for analysis will be obtained from Wikipedia.\n    The following Wikipedia page - https://en.wikipedia.org/wiki/BH_postcode_area\n    provides good information on different Borough and Neighborhoods in Bournmouth City\n    including the postal code.\n    \n    We will use this data to answer the following questions:\n        1. Is the City decent size; how many different Neighbourhoods are present\n        2. How does the Neighborhoods compare to each other, is there a Borough\n           that has more Business opportunities that others?\n        3. Finally what business opportunities exist and some business recommendations", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Methodology", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "    While there are many methods for Data analysis, in this section we will use Python and \n    associated Machine Learning modules.\n    \n    We will discuss some of the modules we will use for our Analysis.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Foursquare API\n    Foursquare is a social location service that allows users to explore the world around them.\n    The Foursquare API can be obtained by signing-up for Developer access. This API access keys\n    allows the application developers to interact with the Foursquare platform. The API itself \n    is a RESTful set of addresses to which you can send requests and receive the output in XML\n    or JSON formats. This data can then be mined based upon our needs.\n    \n    Example of data obtained using API:\n    The API looks like this:\n        'https://api.foursquare.com/v2/venues/explore?&client_id=<client-id>&client_secret=<client_secret>&v=<version>=<latitude>,<longitude>&radius=<span-radius>,limit=10'\n\n    Example of Data Obtained from API:\n       'venue': {'id': '4c70e6a0d97fa1439e87f7ca',\n       'name': 'Kurpark',\n       'location': {'address': 'Kurpromenade',\n        'lat': 48.79974097267919,\n        'lng': 8.438299101627925,\n        'labeledLatLngs': [{'label': 'display',\n          'lat': 48.79974097267919,\n          'lng': 8.438299101627925}],\n        'distance': 287,\n        'cc': 'DE',\n        'city': 'Bad Herrenalb',\n        'state': 'Baden-W\u00fcrttemberg',\n        'country': 'Deutschland',\n        'formattedAddress': ['Kurpromenade', 'Bad Herrenalb', 'Deutschland']},\n       'categories': [{'id': '4bf58dd8d48988d163941735',\n         'name': 'Park',\n         'pluralName': 'Parks',\n         'shortName': 'Park',\n         'icon': {'prefix': 'https://ss3.4sqi.net/img/categories_v2/parks_outdoors/park_',\n          'suffix': '.png'},\n         'primary': True}],\n       'photos': {'count': 0, 'groups': []}},\n      'referralId': 'e-0-4c70e6a0d97fa1439e87f7ca-1'},\n      {'reasons': {'count': 0,\n       'items': [{'summary': 'This spot is popular',\n         'type': 'general',\n         'reasonName': 'globalInteractionReason'}]},\n      \n      Note that in the above example, there is plenty of data for this specific location (kurpark). We can mine the \n      data for location, reviews, url, reviews.etc.\n      \n      We will use this method to get details for all Neighborhoods and extract our desired data,\n      venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng'", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## SciKit-Learn\n    Now that we have the data, our next step is to analyze the data. We will python's SciKit-learn module.\n    Scikit-learn provides a range of supervised and unsupervised learning algorithms via a consistent interface\n    and streamkined API.\n    In this section, we will use scikits normalization algorithm OneHot Encoding. This is to normalize the data so\n    that one or more variable does not skew our results. This method typically converts the categorical variables\n    into numerical values.\n\n    One other important module is the K-means clustering. This is one of the popular clustering algorithm. \n    The goal of this algorithm is to find groups(clusters) in the given data set.\n    \n    Algorithm:\n    Our algorithm works as follows; we have different Neighborhoods say x1,x2,x3,...,xnx_1, x_2, x_3, ..., x_n and value of K\n    Step 1 - Pick K random points as cluster centers called centroids.\n    Step 2 - Assign each xi to nearest cluster by calculating its distance to each centroid.\n    Step 3 - Find new cluster center by taking the average of the assigned points.\n    Step 4 - Repeat Step 2 and 3 until none of the cluster assignments change.\n    \n    This logic brings Neighbourhoods that are similar together. We will cluster our dataset and determine the top 5 clusters.\n    For examples, the neighborhoods that have pubs, or restaurants are grouped together. (like Bournmouth and Poole)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Plotting packages - matplotlib and Folium\n    Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. \n    It provides an object-oriented API for embedding plots into applications.\n    \n    Folium is a powerful data visualization library in Python that is built on top of matplotlib. It help people visualize \n    geospatial data. With Folium, one can create a map of any location in the world using the latitude and longitude values.\n    \n    In this section we will import matplot and Folium and then we will cluster the Neighborhoods and plot Folium geospatial map\n    to visualize the cluster of Neighborhoods on the map. A visual representation in most cases is easy to understand\n    Example: If we want to see where in the map all German Restaurants are located, it becomes possible using this approach.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Methodology Details\nThe following is the high-level summary of the approach. This is categorized into different sections for ease of understanding:\n\nSection-1\n- We use the Python module BeautifulSoup scrape the data from the wikipage. The data we are \n  interested are PostalCode, Borough and Neighborhoods (https://en.wikipedia.org/wiki/BH_postcode_area)                                                       )\n- Then we obtain the latitude and longitude values using geolocator module\n\nSection-2\n- Obtain the Venue details for each of the Neighborhoods using Foursquare APIs\n- Next we get the top 10 Venue with-in the given area span\n\n\nSection-3\n- We can then find the top 10 Venues for each of the Neighborhoods\n- Then categorize our results in a DataFrame\n- We then use K-means to Cluster the Neighborhoods that are similar\n- This is then marked onto the map as cluster of Neighborhoods\n- Now we have sufficient data to examine the top 5 Neighborhood clusters\n- We can also plot the clusters on the map using Folium package\n   ", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}